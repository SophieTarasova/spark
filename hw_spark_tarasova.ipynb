{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "processed-tomato",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1564</td><td>application_1645475281079_151144</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://os-4901.homecredit.ru:8088/proxy/application_1645475281079_151144/\">Link</a></td><td><a target=\"_blank\" href=\"http://os-4895.homecredit.ru:8042/node/containerlogs/container_1645475281079_151144_01_000001/dksadykova\">Link</a></td><td>dksadykova</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2"
     ]
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "specialized-conjunction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-mentor",
   "metadata": {},
   "source": [
    "#### 1. Let's download all our csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "balanced-academy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/user/dksadykova/hse_spark_hw_sonya/*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-contamination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = sc.textFile(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-johnston",
   "metadata": {},
   "source": [
    "#### 2. Check that everything has been downloaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "organizational-particular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010"
     ]
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-annex",
   "metadata": {},
   "source": [
    "#### As we can see, our dataset is not empty and the first string is shown as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-louis",
   "metadata": {},
   "source": [
    "#### 3. Let's search for the top most popular words in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "going-sessions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_df = dataset.flatMap(lambda x: x.split(' ')).map(lambda x: (x,1)).reduceByKey(lambda x,y:x+y)\\\n",
    ".map(lambda x: (x[1], x[0])).sortByKey(False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "shared-median",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 199\n",
      "John 112\n",
      "the 95\n",
      "of 88\n",
      "Michael 83\n",
      "James 71\n",
      "David 63\n",
      "Robert 50\n",
      "Peter 49\n",
      "Richard 42"
     ]
    }
   ],
   "source": [
    "for i in range(10):    print(top_df[i][1],top_df[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-rebate",
   "metadata": {},
   "source": [
    "#### As we can see, the most popular word is an article - 'the' - as well as some directors name (because dataset is dedicated to movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-billy",
   "metadata": {},
   "source": [
    "#### 4. Before we make any further calculations, we need to convert our dataset into dataframe, so it would be easier to analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "framed-composer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema_s = 'line'\n",
    "fields = [StructField(field_name, StringType(), True) for field_name in schema_s.split()]\n",
    "schema = StructType(fields)\n",
    "dataset_count = dataset.take(dataset.count())\n",
    "dataset_mapped = sc.parallelize(dataset_count)\n",
    "dataset_mapped = dataset_mapped.map(lambda x:[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "domestic-yukon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe = spark.createDataFrame(dataset_mapped, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-brunswick",
   "metadata": {},
   "source": [
    "#### 4. After we have created the dataframe, let's calculate how many words it consists of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "following-glass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe = dataframe.withColumn('word_count', f.size(f.split(f.col('line'), ' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "greek-jersey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(sum(word_count)=16395)]"
     ]
    }
   ],
   "source": [
    "dataframe.select(f.sum('word_count')).collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-attraction",
   "metadata": {},
   "source": [
    "##### This means that there are more than 15k words in this file, which makes it suitable for relevant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-price",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
